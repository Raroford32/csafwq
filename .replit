modules = ["python-3.11"]

[nix]
channel = "stable-24_05"

[workflows]
runButton = "Project"

[[workflows.workflow]]
name = "Project"
mode = "parallel"
author = "agent"

[[workflows.workflow.tasks]]
task = "workflow.run"
args = "Run Distributed LLM Inference System"

[[workflows.workflow.tasks]]
task = "workflow.run"
args = "Distributed LLM Inference"

[[workflows.workflow.tasks]]
task = "workflow.run"
args = "Check Ray"

[[workflows.workflow.tasks]]
task = "workflow.run"
args = "Check Ray Environment"

[[workflows.workflow]]
name = "Run Distributed LLM Inference System"
author = "agent"

[workflows.workflow.metadata]
agentRequireRestartOnSave = false

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "python main.py"
waitForPort = 8000

[[workflows.workflow]]
name = "Distributed LLM Inference"
author = "agent"

[workflows.workflow.metadata]
agentRequireRestartOnSave = false

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "python main.py"
waitForPort = 8000

[[workflows.workflow]]
name = "Check Ray"
author = "agent"

[workflows.workflow.metadata]
agentRequireRestartOnSave = false

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "python check_ray.py"

[[workflows.workflow]]
name = "Check Ray Environment"
author = "agent"

[workflows.workflow.metadata]
agentRequireRestartOnSave = false

[[workflows.workflow.tasks]]
task = "shell.exec"
args = "which python && python --version && pip list | grep ray && pip show ray"

[deployment]
run = ["sh", "-c", "python main.py"]

[[ports]]
localPort = 46443
externalPort = 3001

[[ports]]
localPort = 57223
externalPort = 6000

[[ports]]
localPort = 61578
externalPort = 3000

[[ports]]
localPort = 62823
externalPort = 80

[[ports]]
localPort = 62898
externalPort = 5000

[[ports]]
localPort = 63709
externalPort = 3003

[[ports]]
localPort = 63763
externalPort = 4200
